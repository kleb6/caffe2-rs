/*!
  | This file is generated by nnapi/codegen.py
  |
  */

crate::ix!();

//-------------------------------------------[.cpp/pytorch/aten/src/ATen/nnapi/nnapi_wrapper.h]

pub struct NnapiWrapper {
    get_device_count:         fn(num_devices: *mut u32) -> i32,
    get_device:               fn(dev_index: u32, device: *mut *mut ANeuralNetworksDevice) -> i32,
    device_get_name:          fn(device: *const ANeuralNetworksDevice, name: *const *const u8) -> i32,
    device_get_version:       fn(device: *const ANeuralNetworksDevice, version: *const *const u8) -> i32,
    device_get_feature_level: fn(device: *const ANeuralNetworksDevice, feature_level: *mut i64) -> i32,

    model_get_supported_operations_for_devices: fn(
            model:         *const ANeuralNetworksModel,
            devices:       *const *const ANeuralNetworksDevice,
            num_devices:   u32,
            supported_ops: *mut bool
    ) -> i32,

    compilation_create_for_devices: fn(
            model:       *mut ANeuralNetworksModel,
            devices:     *const *const ANeuralNetworksDevice,
            num_devices: u32,
            compilation: *mut *mut ANeuralNetworksCompilation
    ) -> i32,

    execution_compute: fn(execution: *mut ANeuralNetworksExecution) -> i32,

    memory_create_from_fd: fn(
            size:    usize,
            protect: i32,
            fd:      i32,
            offset:  usize,
            memory:  *mut *mut ANeuralNetworksMemory
    ) -> i32,

    memory_free:       fn(memory: *mut ANeuralNetworksMemory) -> (),
    model_create:      fn(model: *mut *mut ANeuralNetworksModel) -> i32,
    model_free:        fn(model: *mut ANeuralNetworksModel) -> (),
    model_finish:      fn(model: *mut ANeuralNetworksModel) -> i32,
    model_add_operand: fn(model: *mut ANeuralNetworksModel, ty: *const ANeuralNetworksOperandType) -> i32,

    model_set_operand_value:                    fn(
            model:  *mut ANeuralNetworksModel,
            index:  i32,
            buffer: *const c_void,
            length: usize
    ) -> i32,

    model_set_operand_value_from_memory:        fn(
            model:  *mut ANeuralNetworksModel,
            index:  i32,
            memory: *const ANeuralNetworksMemory,
            offset: usize,
            length: usize
    ) -> i32,

    model_add_operation:                        fn(
            model:        *mut ANeuralNetworksModel,
            ty:           ANeuralNetworksOperationType,
            input_count:  u32,
            inputs:       *const u32,
            output_count: u32,
            outputs:      *const u32
    ) -> i32,

    model_identify_inputs_and_outputs:          fn(
            model:        *mut ANeuralNetworksModel,
            input_count:  u32,
            inputs:       *const u32,
            output_count: u32,
            outputs:      *const u32
    ) -> i32,

    model_relax_computation_float_32to_float16: fn(model: *mut ANeuralNetworksModel, allow: bool) -> i32,

    compilation_create:            fn(model: *mut ANeuralNetworksModel, compilation: *mut *mut ANeuralNetworksCompilation) -> i32,

    compilation_free:              fn(compilation: *mut ANeuralNetworksCompilation) -> (),

    compilation_set_preference:    fn(compilation: *mut ANeuralNetworksCompilation, preference: i32) -> i32,

    compilation_finish:            fn(compilation: *mut ANeuralNetworksCompilation) -> i32,

    execution_create:              fn(compilation: *mut ANeuralNetworksCompilation, execution: *mut *mut ANeuralNetworksExecution) -> i32,

    execution_free:                fn(execution: *mut ANeuralNetworksExecution) -> (),

    execution_set_input:             fn(
            execution: *mut ANeuralNetworksExecution,
            index:     i32,
            ty:        *const ANeuralNetworksOperandType,
            buffer:    *const c_void,
            length:    usize
    ) -> i32,

    execution_set_input_from_memory: fn(
            execution: *mut ANeuralNetworksExecution,
            index:     i32,
            ty:        *const ANeuralNetworksOperandType,
            memory:    *const ANeuralNetworksMemory,
            offset:    usize,
            length:    usize
    ) -> i32,

    execution_set_output:                    fn(
            execution: *mut ANeuralNetworksExecution,
            index:     i32,
            ty:        *const ANeuralNetworksOperandType,
            buffer:    *mut c_void,
            length:    usize
    ) -> i32,

    execution_set_output_from_memory:        fn(
            execution: *mut ANeuralNetworksExecution,
            index:     i32,
            ty:        *const ANeuralNetworksOperandType,
            memory:    *const ANeuralNetworksMemory,
            offset:    usize,
            length:    usize
    ) -> i32,

    execution_start_compute:  fn(execution: *mut ANeuralNetworksExecution, event: *mut *mut ANeuralNetworksEvent) -> i32,

    event_wait:               fn(event: *mut ANeuralNetworksEvent) -> i32,

    event_free:               fn(event: *mut ANeuralNetworksEvent) -> (),

    execution_get_output_operand_rank:       fn(
            execution: *mut ANeuralNetworksExecution,
            index:     i32,
            rank:      *mut u32
    ) -> i32,

    execution_get_output_operand_dimensions: fn(
            execution:  *mut ANeuralNetworksExecution,
            index:      i32,
            dimensions: *mut u32
    ) -> i32,
}

#[cfg(__cplusplus)]
pub fn nnapi_wrapper_load(
        nnapi:       *mut *mut NnapiWrapper,
        check_nnapi: *mut *mut NnapiWrapper)  {
    
    todo!();
        /*
        
        */
}

//-------------------------------------------[.cpp/pytorch/aten/src/ATen/nnapi/nnapi_wrapper.cpp]

lazy_static!{
    /*
    static int loaded = 0;
    static struct nnapi_wrapper nnapi_;
    static struct nnapi_wrapper check_nnapi_;
    */
}

pub fn check_get_device_count(num_devices: *mut u32) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_._getDeviceCount);
      int ret = nnapi_._getDeviceCount(numDevices);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "_getDeviceCount", "failed with error ", ret
      );
      return ret;
        */
}

pub fn check_get_device(
        dev_index: u32,
        device:    *mut *mut ANeuralNetworksDevice) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_._getDevice);
      int ret = nnapi_._getDevice(devIndex,device);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "_getDevice", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_device_get_name(
        device: *const ANeuralNetworksDevice,
        name:   *const *const u8) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Device_getName);
      int ret = nnapi_.Device_getName(device,name);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Device_getName", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_device_get_version(
        device:  *const ANeuralNetworksDevice,
        version: *const *const u8) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Device_getVersion);
      int ret = nnapi_.Device_getVersion(device,version);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Device_getVersion", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_device_get_feature_level(
        device:        *const ANeuralNetworksDevice,
        feature_level: *mut i64) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Device_getFeatureLevel);
      int ret = nnapi_.Device_getFeatureLevel(device,featureLevel);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Device_getFeatureLevel", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_get_supported_operations_for_devices(
        model:         *const ANeuralNetworksModel,
        devices:       *const *const ANeuralNetworksDevice,
        num_devices:   u32,
        supported_ops: *mut bool) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_getSupportedOperationsForDevices);
      int ret = nnapi_.Model_getSupportedOperationsForDevices(model,devices,numDevices,supportedOps);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_getSupportedOperationsForDevices", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_compilation_create_for_devices(
        model:       *mut ANeuralNetworksModel,
        devices:     *const *const ANeuralNetworksDevice,
        num_devices: u32,
        compilation: *mut *mut ANeuralNetworksCompilation) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Compilation_createForDevices);
      int ret = nnapi_.Compilation_createForDevices(model,devices,numDevices,compilation);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Compilation_createForDevices", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_compute(execution: *mut ANeuralNetworksExecution) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_compute);
      int ret = nnapi_.Execution_compute(execution);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_compute", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_memory_create_from_fd(
        size:    usize,
        protect: i32,
        fd:      i32,
        offset:  usize,
        memory:  *mut *mut ANeuralNetworksMemory) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Memory_createFromFd);
      int ret = nnapi_.Memory_createFromFd(size,protect,fd,offset,memory);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Memory_createFromFd", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_memory_free(memory: *mut ANeuralNetworksMemory)  {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Memory_free);
      nnapi_.Memory_free(memory);
        */
}


pub fn check_model_create(model: *mut *mut ANeuralNetworksModel) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_create);
      int ret = nnapi_.Model_create(model);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_create", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_free(model: *mut ANeuralNetworksModel)  {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_free);
      nnapi_.Model_free(model);
        */
}


pub fn check_model_finish(model: *mut ANeuralNetworksModel) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_finish);
      int ret = nnapi_.Model_finish(model);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_finish", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_add_operand(
        model: *mut ANeuralNetworksModel,
        ty:    *const ANeuralNetworksOperandType) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_addOperand);
      int ret = nnapi_.Model_addOperand(model,type);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_addOperand", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_set_operand_value(
        model:  *mut ANeuralNetworksModel,
        index:  i32,
        buffer: *const c_void,
        length: usize) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_setOperandValue);
      int ret = nnapi_.Model_setOperandValue(model,index,buffer,length);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_setOperandValue", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_set_operand_value_from_memory(
        model:  *mut ANeuralNetworksModel,
        index:  i32,
        memory: *const ANeuralNetworksMemory,
        offset: usize,
        length: usize) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_setOperandValueFromMemory);
      int ret = nnapi_.Model_setOperandValueFromMemory(model,index,memory,offset,length);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_setOperandValueFromMemory", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_add_operation(
        model:        *mut ANeuralNetworksModel,
        ty:           ANeuralNetworksOperationType,
        input_count:  u32,
        inputs:       *const u32,
        output_count: u32,
        outputs:      *const u32) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_addOperation);
      int ret = nnapi_.Model_addOperation(model,type,inputCount,inputs,outputCount,outputs);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_addOperation", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_identify_inputs_and_outputs(
        model:        *mut ANeuralNetworksModel,
        input_count:  u32,
        inputs:       *const u32,
        output_count: u32,
        outputs:      *const u32) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_identifyInputsAndOutputs);
      int ret = nnapi_.Model_identifyInputsAndOutputs(model,inputCount,inputs,outputCount,outputs);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_identifyInputsAndOutputs", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_model_relax_computation_float_32to_float16(
        model: *mut ANeuralNetworksModel,
        allow: bool) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Model_relaxComputationFloat32toFloat16);
      int ret = nnapi_.Model_relaxComputationFloat32toFloat16(model,allow);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Model_relaxComputationFloat32toFloat16", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_compilation_create(
        model:       *mut ANeuralNetworksModel,
        compilation: *mut *mut ANeuralNetworksCompilation) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Compilation_create);
      int ret = nnapi_.Compilation_create(model,compilation);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Compilation_create", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_compilation_free(compilation: *mut ANeuralNetworksCompilation)  {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Compilation_free);
      nnapi_.Compilation_free(compilation);
        */
}


pub fn check_compilation_set_preference(
        compilation: *mut ANeuralNetworksCompilation,
        preference:  i32) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Compilation_setPreference);
      int ret = nnapi_.Compilation_setPreference(compilation,preference);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Compilation_setPreference", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_compilation_finish(compilation: *mut ANeuralNetworksCompilation) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Compilation_finish);
      int ret = nnapi_.Compilation_finish(compilation);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Compilation_finish", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_create(
        compilation: *mut ANeuralNetworksCompilation,
        execution:   *mut *mut ANeuralNetworksExecution) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_create);
      int ret = nnapi_.Execution_create(compilation,execution);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_create", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_free(execution: *mut ANeuralNetworksExecution)  {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_free);
      nnapi_.Execution_free(execution);
        */
}


pub fn check_execution_set_input(
        execution: *mut ANeuralNetworksExecution,
        index:     i32,
        ty:        *const ANeuralNetworksOperandType,
        buffer:    *const c_void,
        length:    usize) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_setInput);
      int ret = nnapi_.Execution_setInput(execution,index,type,buffer,length);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_setInput", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_set_input_from_memory(
        execution: *mut ANeuralNetworksExecution,
        index:     i32,
        ty:        *const ANeuralNetworksOperandType,
        memory:    *const ANeuralNetworksMemory,
        offset:    usize,
        length:    usize) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_setInputFromMemory);
      int ret = nnapi_.Execution_setInputFromMemory(execution,index,type,memory,offset,length);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_setInputFromMemory", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_set_output(
        execution: *mut ANeuralNetworksExecution,
        index:     i32,
        ty:        *const ANeuralNetworksOperandType,
        buffer:    *mut c_void,
        length:    usize) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_setOutput);
      int ret = nnapi_.Execution_setOutput(execution,index,type,buffer,length);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_setOutput", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_set_output_from_memory(
        execution: *mut ANeuralNetworksExecution,
        index:     i32,
        ty:        *const ANeuralNetworksOperandType,
        memory:    *const ANeuralNetworksMemory,
        offset:    usize,
        length:    usize) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_setOutputFromMemory);
      int ret = nnapi_.Execution_setOutputFromMemory(execution,index,type,memory,offset,length);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_setOutputFromMemory", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_start_compute(
        execution: *mut ANeuralNetworksExecution,
        event:     *mut *mut ANeuralNetworksEvent) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_startCompute);
      int ret = nnapi_.Execution_startCompute(execution,event);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_startCompute", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_event_wait(event: *mut ANeuralNetworksEvent) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Event_wait);
      int ret = nnapi_.Event_wait(event);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Event_wait", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_event_free(event: *mut ANeuralNetworksEvent)  {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Event_free);
      nnapi_.Event_free(event);
        */
}


pub fn check_execution_get_output_operand_rank(
        execution: *mut ANeuralNetworksExecution,
        index:     i32,
        rank:      *mut u32) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_getOutputOperandRank);
      int ret = nnapi_.Execution_getOutputOperandRank(execution,index,rank);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_getOutputOperandRank", "failed with error ", ret
      );
      return ret;
        */
}


pub fn check_execution_get_output_operand_dimensions(
        execution:  *mut ANeuralNetworksExecution,
        index:      i32,
        dimensions: *mut u32) -> i32 {
    
    todo!();
        /*
            CAFFE_ENFORCE(nnapi_.Execution_getOutputOperandDimensions);
      int ret = nnapi_.Execution_getOutputOperandDimensions(execution,index,dimensions);
      // TODO: Maybe add better logging here.
      CAFFE_ENFORCE(
        ret == ANEURALNETWORKS_NO_ERROR,
        "Execution_getOutputOperandDimensions", "failed with error ", ret
      );
      return ret;
        */
}


pub fn nnapi_wrapper_load(
        nnapi:       *mut *mut NnapiWrapper,
        check_nnapi: *mut *mut NnapiWrapper)  {
    
    todo!();
        /*
            #ifdef _WIN32
      TORCH_CHECK(false, "Running NNAPI models is not supported on Windows.");
    #else
      if (!loaded) {
        // Clear error flag.
        dlerror();
        void* handle = dlopen("libneuralnetworks.so", RTLD_LAZY | RTLD_LOCAL);
        CAFFE_ENFORCE(handle, "Failed to load libneuralnetworks.so ", dlerror());
        *(void**)&nnapi_._getDeviceCount = dlsym(handle, "ANeuralNetworks_getDeviceCount");
        check_nnapi_._getDeviceCount = check__getDeviceCount;
        *(void**)&nnapi_._getDevice = dlsym(handle, "ANeuralNetworks_getDevice");
        check_nnapi_._getDevice = check__getDevice;
        *(void**)&nnapi_.Device_getName = dlsym(handle, "ANeuralNetworksDevice_getName");
        check_nnapi_.Device_getName = check_Device_getName;
        *(void**)&nnapi_.Device_getVersion = dlsym(handle, "ANeuralNetworksDevice_getVersion");
        check_nnapi_.Device_getVersion = check_Device_getVersion;
        *(void**)&nnapi_.Device_getFeatureLevel = dlsym(handle, "ANeuralNetworksDevice_getFeatureLevel");
        check_nnapi_.Device_getFeatureLevel = check_Device_getFeatureLevel;
        *(void**)&nnapi_.Model_getSupportedOperationsForDevices = dlsym(handle, "ANeuralNetworksModel_getSupportedOperationsForDevices");
        check_nnapi_.Model_getSupportedOperationsForDevices = check_Model_getSupportedOperationsForDevices;
        *(void**)&nnapi_.Compilation_createForDevices = dlsym(handle, "ANeuralNetworksCompilation_createForDevices");
        check_nnapi_.Compilation_createForDevices = check_Compilation_createForDevices;
        *(void**)&nnapi_.Execution_compute = dlsym(handle, "ANeuralNetworksExecution_compute");
        check_nnapi_.Execution_compute = check_Execution_compute;
        *(void**)&nnapi_.Memory_createFromFd = dlsym(handle, "ANeuralNetworksMemory_createFromFd");
        check_nnapi_.Memory_createFromFd = check_Memory_createFromFd;
        *(void**)&nnapi_.Memory_free = dlsym(handle, "ANeuralNetworksMemory_free");
        check_nnapi_.Memory_free = check_Memory_free;
        *(void**)&nnapi_.Model_create = dlsym(handle, "ANeuralNetworksModel_create");
        check_nnapi_.Model_create = check_Model_create;
        *(void**)&nnapi_.Model_free = dlsym(handle, "ANeuralNetworksModel_free");
        check_nnapi_.Model_free = check_Model_free;
        *(void**)&nnapi_.Model_finish = dlsym(handle, "ANeuralNetworksModel_finish");
        check_nnapi_.Model_finish = check_Model_finish;
        *(void**)&nnapi_.Model_addOperand = dlsym(handle, "ANeuralNetworksModel_addOperand");
        check_nnapi_.Model_addOperand = check_Model_addOperand;
        *(void**)&nnapi_.Model_setOperandValue = dlsym(handle, "ANeuralNetworksModel_setOperandValue");
        check_nnapi_.Model_setOperandValue = check_Model_setOperandValue;
        *(void**)&nnapi_.Model_setOperandValueFromMemory = dlsym(handle, "ANeuralNetworksModel_setOperandValueFromMemory");
        check_nnapi_.Model_setOperandValueFromMemory = check_Model_setOperandValueFromMemory;
        *(void**)&nnapi_.Model_addOperation = dlsym(handle, "ANeuralNetworksModel_addOperation");
        check_nnapi_.Model_addOperation = check_Model_addOperation;
        *(void**)&nnapi_.Model_identifyInputsAndOutputs = dlsym(handle, "ANeuralNetworksModel_identifyInputsAndOutputs");
        check_nnapi_.Model_identifyInputsAndOutputs = check_Model_identifyInputsAndOutputs;
        *(void**)&nnapi_.Model_relaxComputationFloat32toFloat16 = dlsym(handle, "ANeuralNetworksModel_relaxComputationFloat32toFloat16");
        check_nnapi_.Model_relaxComputationFloat32toFloat16 = check_Model_relaxComputationFloat32toFloat16;
        *(void**)&nnapi_.Compilation_create = dlsym(handle, "ANeuralNetworksCompilation_create");
        check_nnapi_.Compilation_create = check_Compilation_create;
        *(void**)&nnapi_.Compilation_free = dlsym(handle, "ANeuralNetworksCompilation_free");
        check_nnapi_.Compilation_free = check_Compilation_free;
        *(void**)&nnapi_.Compilation_setPreference = dlsym(handle, "ANeuralNetworksCompilation_setPreference");
        check_nnapi_.Compilation_setPreference = check_Compilation_setPreference;
        *(void**)&nnapi_.Compilation_finish = dlsym(handle, "ANeuralNetworksCompilation_finish");
        check_nnapi_.Compilation_finish = check_Compilation_finish;
        *(void**)&nnapi_.Execution_create = dlsym(handle, "ANeuralNetworksExecution_create");
        check_nnapi_.Execution_create = check_Execution_create;
        *(void**)&nnapi_.Execution_free = dlsym(handle, "ANeuralNetworksExecution_free");
        check_nnapi_.Execution_free = check_Execution_free;
        *(void**)&nnapi_.Execution_setInput = dlsym(handle, "ANeuralNetworksExecution_setInput");
        check_nnapi_.Execution_setInput = check_Execution_setInput;
        *(void**)&nnapi_.Execution_setInputFromMemory = dlsym(handle, "ANeuralNetworksExecution_setInputFromMemory");
        check_nnapi_.Execution_setInputFromMemory = check_Execution_setInputFromMemory;
        *(void**)&nnapi_.Execution_setOutput = dlsym(handle, "ANeuralNetworksExecution_setOutput");
        check_nnapi_.Execution_setOutput = check_Execution_setOutput;
        *(void**)&nnapi_.Execution_setOutputFromMemory = dlsym(handle, "ANeuralNetworksExecution_setOutputFromMemory");
        check_nnapi_.Execution_setOutputFromMemory = check_Execution_setOutputFromMemory;
        *(void**)&nnapi_.Execution_startCompute = dlsym(handle, "ANeuralNetworksExecution_startCompute");
        check_nnapi_.Execution_startCompute = check_Execution_startCompute;
        *(void**)&nnapi_.Event_wait = dlsym(handle, "ANeuralNetworksEvent_wait");
        check_nnapi_.Event_wait = check_Event_wait;
        *(void**)&nnapi_.Event_free = dlsym(handle, "ANeuralNetworksEvent_free");
        check_nnapi_.Event_free = check_Event_free;
        *(void**)&nnapi_.Execution_getOutputOperandRank = dlsym(handle, "ANeuralNetworksExecution_getOutputOperandRank");
        check_nnapi_.Execution_getOutputOperandRank = check_Execution_getOutputOperandRank;
        *(void**)&nnapi_.Execution_getOutputOperandDimensions = dlsym(handle, "ANeuralNetworksExecution_getOutputOperandDimensions");
        check_nnapi_.Execution_getOutputOperandDimensions = check_Execution_getOutputOperandDimensions;
        loaded = 1;
      }
      *nnapi = &nnapi_;
      *check_nnapi = &check_nnapi_;
    #endif
        */
}
