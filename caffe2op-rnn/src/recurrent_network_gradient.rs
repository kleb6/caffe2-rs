crate::ix!();

///--------------------------------
#[USE_OPERATOR_CONTEXT_FUNCTIONS]
pub struct RecurrentNetworkGradientOp<Context> {
    storage:               OperatorStorage,
    context:               Context,
    step_net_def:          NetDef,
    shared_ws:             *mut Workspace,
    enable_rnn_executor:   bool,
    rnn_executor:          Box<RecurrentNetworkExecutorBase>,
    links:                 Vec<Link>,
    params:                Vec<Param>,
    recurrent_gradients:   Vec<RecurrentGradient>,
    timestep:              String,

    /// For now we support only one input sequence
    num_sequences:         i32, //{1};
    recurrent_input_ids:   Vec<i32>,
    grad_inputs:           Vec<i32>,
}

impl<Context> RecurrentNetworkGradientOp<Context> {
    
    pub fn new(operator_def: &OperatorDef, ws: *mut Workspace) -> Self {
        todo!();
        /*
            : Operator<Context>(operator_def, ws),
            sharedWs_(ws),
            enable_rnn_executor_(this->template GetSingleArgument<bool>( "enable_rnn_executor", false)),
            timestep_(this->template GetSingleArgument<std::string>( "timestep", "timestep")),
            gradInputs_( this->template GetRepeatedArgument<int32_t>("outputs_with_grads")) 

        CAFFE_ENFORCE(ws);

        stepNetDef_ = detail::extractNetDef(operator_def, "backward_step_net");

        links_ = constructLinks();
        params_ = constructParams(operator_def);
        recurrentGradients_ = constructRecurrentGradients(operator_def);
        recurrentInputIds_ = this->template GetRepeatedArgument<int32_t>(
            "initial_recurrent_state_ids");

        /* Add operators to the backward step net to handle accumulation of
           gradients over timesteps
        */
        stepNetDef_.add_external_input(timestep_);

        AddGradientInputAccumulationOps(operator_def);
        detail::AddApplyLinkOps(
            links_, timestep_, operator_def.device_option(), &stepNetDef_);
        AddParamGradientAccumulationOps(operator_def);

        if (FLAGS_caffe2_rnn_executor && enable_rnn_executor_) {
          InitializeExecutor(operator_def);
        }
        */
    }

    /// Renaming maps (generated by memonger.py)
    #[inline] pub fn remapped_name(&mut self, blob_name: String) -> String {
        
        todo!();
        /*
            return this->template GetSingleArgument<std::string>(
            blob_name + ".rename", blob_name);
        */
    }
    
    #[inline] pub fn remapped_link(&mut self, link: &Link) -> Link {
        
        todo!();
        /*
            detail::Link renamed_link = link;
        renamed_link.internal = remappedName(link.internal);
        renamed_link.external = remappedName(link.external);
        return renamed_link;
        */
    }
    
    #[inline] pub fn rename_op_input_output(
        &mut self, 
        from_name: String,
        to_name:   String)  
    {
        todo!();
        /*
            for (int j = 0; j < stepNetDef_.op_size(); j++) {
          auto* op = stepNetDef_.mutable_op(j);
          for (int i = 0; i < op->input_size(); i++) {
            if (op->input(i) == from_name) {
              op->set_input(i, to_name);
            }
          }
          for (int i = 0; i < op->output_size(); i++) {
            if (op->output(i) == from_name) {
              op->set_output(i, to_name);
            }
          }
        }
        */
    }
    
    #[inline] pub fn construct_params(&mut self, operator_def: &OperatorDef) -> Vec<Param> {
        
        todo!();
        /*
            std::vector<detail::Param> params;
        const auto& param = this->template GetRepeatedArgument<int32_t>("param");
        const auto& param_grads =
            this->template GetRepeatedArgument<string>("param_grads");
        CAFFE_ENFORCE(
            param_grads.empty() || param_grads.size() == param.size(),
            param.size(),
            " != ",
            param_grads.size());
        for (int i = 0; i < param.size(); ++i) {
          detail::Param p;
          // Forward inputs come after [outputs_with_grads] gradient inputs
          p.param = operator_def.input(param[i] + gradInputs_.size());
          // See GetRecurrentNetworkGradient to understand offseting here
          p.grad = operator_def.output(i + numSequences_);

          std::string grad_blob =
              param_grads.empty() ? p.grad : remappedName(param_grads[i]);
          p.cellGradient = grad_blob + "_tmpstep";
          params.push_back(p);

          renameOpInputOutput(grad_blob, p.cellGradient);
        }
        return params;
        */
    }
    
    #[inline] pub fn construct_recurrent_gradients(&mut self, operator_def: &OperatorDef) -> Vec<RecurrentGradient> {
        
        todo!();
        /*
            std::vector<detail::RecurrentGradient> rgs;
        const auto& recurrent =
            this->template GetRepeatedArgument<std::string>("recurrent_states");
        const auto& alias_src =
            this->template GetRepeatedArgument<std::string>("alias_src");
        const auto& offset =
            this->template GetRepeatedArgument<int32_t>("alias_offset");

        for (auto i = 0; i < recurrent.size(); ++i) {
          detail::RecurrentGradient rg;
          rg.param = recurrent[i];
          rg.grad = remappedName(recurrent[i] + "_grad");

          for (int j = 0; j < alias_src.size(); ++j) {
            if (alias_src[j] != recurrent[i]) {
              continue;
            }
            int idx = -1;
            for (int k = 0; k < gradInputs_.size(); ++k) {
              if (gradInputs_[k] == j) {
                idx = k;
              }
            }
            if (idx == -1) {
              continue;
            }

            CAFFE_ENFORCE(offset[j] == 1 || offset[j] == -1);
            if (offset[j] == 1) {
              rg.externalGrad = operator_def.input(idx);
            } else if (offset[j] == -1) {
              rg.lastExternalGrad = operator_def.input(idx);
            }
          }
          rg.offset = 1;
          rgs.push_back(rg);
        }
        return rgs;
        */
    }
    
    #[inline] pub fn construct_links(&mut self) -> Vec<Link> {
        
        todo!();
        /*
            std::vector<detail::Link> links;
        detail::extractLinks(
            this,
            "link_internal",
            "link_external",
            "link_offset",
            "link_window",
            &links);
        detail::extractLinks(
            this,
            "backward_link_internal",
            "backward_link_external",
            "backward_link_offset",
            "",
            &links);
        for (int i = 0; i < links.size(); i++) {
          links[i] = remappedLink(links[i]);
        }
        return links;
        */
    }
    
    #[inline] pub fn initialize_executor(&mut self, operator_def: &OperatorDef)  {
        
        todo!();
        /*
            VLOG(1) << "Use RecurrentNetworkExecutor for backward";
        auto recurrent_map = detail::GetRecurrentMapping(links_, true /* backward */);
        rnnExecutor_ = createRNNExecutor<Context>(
          stepNetDef_, recurrent_map, timestep_, ArgumentHelper(operator_def));
        */
    }
    
    #[inline] pub fn add_gradient_input_accumulation_ops(&mut self, operator_def: &OperatorDef)  {
        
        todo!();
        /*
            /**
          * Add ops to the step net to accumulate input gradients.
          */
        std::vector<OperatorDef> ops;
        for (const auto& rg : recurrentGradients_) {
          if (rg.externalGrad.empty()) {
            continue;
          }
          VLOG(1) << "Accumulating into: " << rg.grad << " from " << rg.externalGrad
                  << ", offset: " << rg.offset;

          OperatorDef opdef;
          opdef.set_type("rnn_internal_accumulate_gradient_input");
          opdef.add_input(timestep_);
          opdef.add_input(rg.externalGrad);
          opdef.add_input(rg.grad);
          opdef.add_output(rg.grad);

          // Add also the linked blobs to outputs, to ensure correct
          // chaining.
          for (auto& l : links_) {
            if (rg.grad == l.external) {
              Argument* dep_arg = opdef.add_arg();
              dep_arg->set_name("rnn_dependency." + l.internal);
              dep_arg->set_s(l.internal);
            }
          }

          opdef.mutable_device_option()->CopyFrom(operator_def.device_option());

          Argument* offset_arg = opdef.add_arg();
          offset_arg->set_name("offset");
          offset_arg->set_i(rg.offset);
          ops.push_back(opdef);

          stepNetDef_.add_external_input(rg.externalGrad);
          stepNetDef_.add_external_input(rg.grad);
        }
        detail::PrependOps(ops, &stepNetDef_);
        */
    }
    
    #[inline] pub fn add_param_gradient_accumulation_ops(&mut self, operator_def: &OperatorDef)  {
        
        todo!();
        /*
            // If a user passes in param_grads mapping, we can copy dirrectly
        // form a blob where backward cell net written data to.
        // This becomes handy in a case where gradient from the cell net
        // is an internal blob of the backward cell. This happens, for example,
        // when SumOp is the first op of the cell
        for (const auto& param : params_) {
          OperatorDef opdef;
          opdef.set_type("Sum");
          opdef.add_input(param.grad);
          opdef.add_input(param.cellGradient);
          opdef.add_output(param.grad);
          opdef.mutable_device_option()->CopyFrom(operator_def.device_option());
          stepNetDef_.add_op()->CopyFrom(opdef);
          stepNetDef_.add_external_input(param.grad);
        }
        */
    }
    
    #[inline] pub fn create_shared_blobs(
        &mut self, 
        step_0ws: &Arc<Workspace>,
        shared_blobs_ws: *mut Workspace)  
    {
        todo!();
        /*
            /**
          * Create all output blobs created by ops of the backward step net, they
          * can be shared.
          */
        for (auto& op : stepNetDef_.op()) {
          for (const string& outp : op.output()) {
            if (!step0Ws->HasBlob(outp)) {
              sharedBlobsWs->CreateBlob(outp);
            }
          }
        }
        */
    }

    #[inline] pub fn do_run_with_type<T>(&mut self) -> bool {
        todo!();
        /*
            const auto seqLen = Input(gradInputs_.size()).dim32(0);
            VLOG(1) << "seqLen: " << seqLen;

            const detail::ScratchWorkspaces& scratch =
                this->template Input<detail::ScratchWorkspaces>(InputSize() - 1);
            const std::vector<std::shared_ptr<Workspace>>& stepWorkspaces =
                scratch.stepWorkspaces;
            CAFFE_ENFORCE_GE(stepWorkspaces.size(), seqLen);
            Workspace& sharedBlobsWs = *scratch.sharedBlobsWs.get();

            const auto batchSize = Input(0).dim32(1);
            for (auto& param : params_) {
              auto pBlob = sharedWs_->GetBlob(param.param);
              CAFFE_ENFORCE(pBlob);
              const auto& p = pBlob->template Get<Tensor>();

              auto gBlob = sharedWs_->GetBlob(param.grad);
              CAFFE_ENFORCE(gBlob);
              auto* g = BlobGetMutableTensor(gBlob, Context::GetDeviceType());
              g->ResizeLike(p);
              math::Set<T, Context>(
                  g->numel(),
                  convert::To<float, T>(0.0),
                  g->template mutable_data<T>(),
                  &context_);
            }

            for (auto& rg : recurrentGradients_) {
              auto pBlob = sharedWs_->GetBlob(rg.param);
              CAFFE_ENFORCE(pBlob);
              const auto& p = pBlob->template Get<Tensor>();

              auto gBlob = sharedWs_->CreateBlob(rg.grad);
              CAFFE_ENFORCE(gBlob);
              auto* g = BlobGetMutableTensor(gBlob, Context::GetDeviceType());
              g->ResizeLike(p);
              CAFFE_ENFORCE_EQ(g->dim(), 3);
              const auto timestep = g->numel() / g->size(0);
              // Fill the last timestep with zeros for the gradient
              math::Set<T, Context>(
                  timestep,
                  convert::To<float, T>(0.0),
                  g->template mutable_data<T>() + (g->size(0) - 1) * timestep,
                  &context_);
            }

            // This code assumes that there are several inputs
            // sequences. Actually it is not supported by the rest of the code,
            // and numSequences_ is a constant, equal to 1.
            for (int i = 0; i < numSequences_; ++i) {
              // Offseting as the first gradInputs_.size() inputs of the op
              // are from GO. Then all I(0..N).
              const int gradientInputIndex = i + gradInputs_.size();
              const auto& inputName = this->debug_def().input(gradientInputIndex);
              auto gradientName = remappedName(inputName + "_grad");
              VLOG(1) << "Initializing gradient for input " << gradientInputIndex
                      << " (" << inputName << ") "
                      << " as blob " << gradientName
                      << ". Size: " << Input(gradientInputIndex).numel();
              auto pGradientBlob = sharedWs_->GetBlob(gradientName);
              CAFFE_ENFORCE(pGradientBlob);
              auto* g = BlobGetMutableTensor(pGradientBlob, Context::GetDeviceType());
              g->ResizeLike(Input(gradientInputIndex));
              g->template mutable_data<T>();
            }

            auto accumulateFinalInputGradients = [&]() {
              for (const auto& rg : recurrentGradients_) {
                if (rg.lastExternalGrad.empty()) {
                  continue;
                }
                VLOG(1) << "Accumulating into: " << rg.grad << " from "
                        << rg.lastExternalGrad << " for final time step (sep. blob)";
                auto gBlob = sharedWs_->GetBlob(rg.grad);
                CAFFE_ENFORCE(gBlob);
                auto* g = BlobGetMutableTensor(gBlob, Context::GetDeviceType());

                auto oglastBlob = sharedWs_->GetBlob(rg.lastExternalGrad);
                CAFFE_ENFORCE(oglastBlob);
                const auto& oglast = oglastBlob->template Get<Tensor>();
                CAFFE_ENFORCE_EQ(g->size(1), oglast.size(1));
                CAFFE_ENFORCE_EQ(g->size(2), oglast.size(2));

                const auto t = g->size(0) - 1;
                const auto timestep_size = g->numel() / g->size(0);
                CAFFE_ENFORCE_EQ(timestep_size, oglast.numel());
                T* g_data_with_offset =
                    g->template mutable_data<T>() + t * timestep_size;
                math::Add<T, Context>(
                    timestep_size,
                    oglast.template data<T>(),
                    g_data_with_offset,
                    g_data_with_offset,
                    &context_);
              }
            };

            accumulateFinalInputGradients();

            // Create shared blobs for blobs that can be shared between
            // all timesteps.
            if (stepWorkspaces.size() > 0) {
              CreateSharedBlobs(stepWorkspaces[0], &sharedBlobsWs);
            }
            for (int32_t t = seqLen - 1; t >= 0; --t) {
              if (rnnExecutor_) {
                rnnExecutor_->EnsureTimestepInitialized(
                    t, stepWorkspaces[t].get(), this->observers_list_);
              } else {
                auto* stepNet = stepWorkspaces[t].get()->GetNet(stepNetDef_.name());
                if (stepNet == nullptr) {
                  stepNet = stepWorkspaces[t].get()->CreateNet(stepNetDef_);
                }
                CAFFE_ENFORCE(stepNet);
                stepNet->RunAsync();
              }
            }

            if (rnnExecutor_) {
              rnnExecutor_->RunBackwards(seqLen);
            }

            CAFFE_ENFORCE_EQ(recurrentInputIds_.size(), recurrentGradients_.size());
            for (int i = 0; i < recurrentInputIds_.size(); ++i) {
              // See GetRecurrentNetworkGradient to understand offseting here
              // Outputs of the gradient are inputs of the forward pass.
              // So we need to offset on all inputs that go before recurrent
              // initial ones
              auto outputIdx = i + params_.size() + numSequences_;
              // because first gradInputs_.size() inputs are from GO
              int inputId = recurrentInputIds_[i] + gradInputs_.size();
              VLOG(1) << "Resetting output " << this->debug_def().output(outputIdx)
                      << " like input " << this->debug_def().input(inputId);
              Output(outputIdx)->ResizeLike(Input(inputId));
              T* output_data = Output(outputIdx)->template mutable_data<T>();
              auto pBlob = sharedWs_->GetBlob(recurrentGradients_[i].grad);
              CAFFE_ENFORCE(pBlob);
              auto* p = BlobGetMutableTensor(pBlob, Context::GetDeviceType());

              if (Input(inputId).dim() >= 2) {
                // Gradient states blob should live. And if it gets changed by the
                // backward pass, then output should be changed as well. Thus it should
                // be okay to share data here
                Output(outputIdx)->template ShareExternalPointer<T>(
                    p->template mutable_data<T>());
              } else {
                // We need to do a bunch of Adds any way. So lets not worry about
                // copy / share data here. One way to speed this up could be a kernel
                // which sums up several tensors together instead of going 1 by 1
                const auto recurrentStateSize = Input(inputId).dim32(0);

                math::Set<T, Context>(
                    recurrentStateSize,
                    convert::To<float,T>(0.0),
                    output_data,
                    &context_);

                math::AddStripedBatch<T, Context>(
                    recurrentStateSize,
                    p->template data<T>(),
                    output_data,
                    recurrentStateSize,
                    batchSize,
                    &context_);
              }
            }

            return true;
        */
    }
    
    #[inline] pub fn run_on_device(&mut self) -> bool {
        
        todo!();
        /*
            return DoRunWithType<float>();
        */
    }
}
