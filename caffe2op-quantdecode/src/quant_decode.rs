crate::ix!();

/**
  | Decode tensors based on given codebook,
  | 
  | The codebook is generated by model_quantize.py
  |
  */
#[derive(PartialEq,Eq)]
pub enum QuantDecodeRunTy {
    RUN_ALWAYS,
    RUN_ONCE,
}

#[USE_OPERATOR_FUNCTIONS("CPUContext")]
pub struct QuantDecodeOp<const QuantDecodeRun: QuantDecodeRunTy> {
    storage: OperatorStorage,
    context: CPUContext,
    has_run: bool, // default = false
}

impl<const QuantDecodeRun: QuantDecodeRunTy> QuantDecodeOp<QuantDecodeRun> {
    
    pub fn new<Args>(args: Args) -> Self {
        todo!();
        /*
            : Operator<CPUContext>(std::forward<Args>(args)...)
        */
    }
    
    #[inline] pub fn run_on_device(&mut self) -> bool {
        
        todo!();
        /*
            CAFFE_ENFORCE_GT(InputSize(), 1);
        // first input is the codebook
        CAFFE_ENFORCE_EQ(InputSize(), OutputSize() + 1);

        const auto& codebook = Input(0);
        CAFFE_ENFORCE(codebook.template IsType<float>(), codebook.dtype().name());

        for (int i = 0; i < OutputSize(); i++) {
          auto& ci = Input(i + 1);
          auto* co = Output(i);

          DecodeGeneral(
              codebook,
              ci,
              nullptr,
              co,
              /*resizeOnly=*/QuantDecodeRun == QuantDecodeRunTy::RUN_ONCE &&
                  hasRun_);
        }
        hasRun_ = true;
        return true;
        */
    }
}
