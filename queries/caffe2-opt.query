hello! could you please help me write a crate-description for the rust crate "caffe2-opt" containing the following symbols? not all of the symbols are defined in this crate, but they are used somehow (please do not explicitly list the symbols, or write anything other than a simple description.  no description header is necessary. however, please be descriptive and as thorough as possible without making too many assumptions) :A
Add
And
Arc
ArgumentHelper
AveragePool
BATCH
BIAS
BitRowwise
BitRowwiseQuantized
BitRowwiseSparse
Both
Bound
BoundShapeInferencer
BoundShapeInferencerBase
BoundShapeInferencerBaseTrait
BoundShapeInferencerRegistry
BoundShapeSpec
C
COMPRESSED
CONSTANT
CONSTANTS
Cannot
Caught
Check
CheckAndSetTensorBoundShape
Clear
ComputeEqualizationScale
Concat
ConstantFill
Conv
ConvPackWeight
ConvRelu
ConvertToVec
D
DATA
DEFAULT
DNNLOWP
DataType
Depending
Dequantize
Didn
Dim
DimType
Doing
ERROR
EndsWith
Enforce
EnforceNotMet
EnsureShapeNames
Extract
FC
FCPackWeight
FCTransposed
FEATURE
FLOAT
FbFCPacked
FbGemmPack
Fill
First
FloatToFused
FloatToHalf
For
Force
From
GE
GT
GenQuantParams
GenQuantParamsMinMax
Get
GetDimFromOrderString
GetRepeatedArgument
GetSingleArgument
GivenIntTensorFill
GivenTensor
GivenTensorFill
HalfFloatToFused
HalfToFused
Handle
HasArgument
HashMap
INDICES
INFO
INT
If
In
Infer
InferBoundShapeAndType
InferCommonOp
InferConcat
InferConcatInputs
InferElementwiseOp
InferElementwiseOpInput
InferFC
InferGivenTensorFill
InferInt
InferLengthsRangeFill
InferLpNorm
InferOps
InferOutput
InferQuantizationTransformation
InferReshape
InferShape
InferSoftmax
InferSparseLengthsSum
InferSparseLengthsSumSparseLookup
InferTensor
InferTile
InferUnPackRecords
Infers
Initialize
Initializes
Input
Int
K
LE
LOG
LengthsRangeFill
LpNorm
MAPPING
MAX
Make
MaxPool
Mismatched
More
Mul
NCHW
NetDef
Note
OF
OpSchema
OpSchemaRegistry
OperatorDef
Option
Print
QuantSchemeBlobFill
Quantize
QuantizeInput
Relu
RepeatedField
Reshape
Schema
Self
Set
SetTensorBoundShapeIfNotExist
Shape
ShapeInfo
ShapeInfoMap
SigridTransform
SizeFromDim
SizeToDim
Skipping
Softmax
Sparse
SparseLengthsSum
SparseLengthsSumFused
SparseLengthsSumSparseLookup
SparseLengthsWeightedSum
SparseLengthsWeightedSumFused
Special
Standard
StartsWith
String
SumRelu
TODO
TensorBoundShape
TensorProto
TensorShape
The
Then
This
Tile
UINT
UNDEFINED
UNKNOWN
UnPackRecords
Undefined
Upper
VLOG
WARNING
WEIGHT
We
When
Workspace
Y
dimTypeIsSet
dimTypes
firstDimType
getBoundShapeInferencer
getDimType
getShapeIsFinal
inferFC
inferFinished
isSparse
kSlsOps
setDimType
setDimTypeWithFirst
setShapeIsFinal
takePrecedenceOver
ASSERT
Add
B
BATCH
BatchGather
BatchMatMul
BitRowwise
BitRowwiseQuantized
BitRowwiseSparse
BoundShapeInference
BoundShapeInferencer
BoundShapeSpec
Bout
Bucketize
CONSTANT
Cannot
Checking
Combo
Concat
ConcatInferInputBackwards
ConcatMissingInput
ConstantFill
Copy
CopyFrom
Cout
CreateOperatorDef
D
DEFAULT
Data
DataType
DimType
EB
EXPECT
ElementwiseInferInputBackwards
ElementwiseOp
FC
FCTransposed
FEATURE
FLOAT
Flatten
FloatToFused
Fout
Gout
INFO
INT
In
Indices
IndicesOut
InferBoundShapeAndType
Int
LOG
Lengths
LengthsOut
LengthsRangeFill
LpNorm
MAX
MakeArgument
Mapping
Mul
NetDef
OF
Option
Out
Outt
PrintShapeInfo
Quantization
Quantize
QuantizeInferInputBackwards
Remapping
Reshape
See
ShapeInfo
ShapeInfoMap
Softmax
SparseLengthsSum
SparseLengthsSumFused
SparseLengthsSumSparseLookup
Split
String
TODO
TRUE
TensorBoundShape
TensorProto
TensorShape
Tile
UINT
W
Weights
WeightsOut
Y
Z
getDimType
makeTensorInfo
setDimType
verifyShapeInfo
A
Add
AddArgument
Adding
Annnote
Apply
ArgumentHelper
Asssume
AsyncIf
At
BACKEND
BATCH
BackendTransformOptions
BackendTransformerBase
Backned
BitRowwise
BitRowwiseSparse
BlackBoxPredictor
BlobGetMutableTensor
BlobGetTensor
Boundary
Build
C
CONSTANT
CPU
Caffe
Cannot
Caught
Check
Clear
Concat
Convert
CopyBytesSameDevice
CopyFrom
CreateBlob
CreateOperatorDef
Cutting
DATATYPE
DEFAULT
DEVICE
DataType
Debugging
Determine
DeviceOption
DimType
Don
Drop
ENABLE
ERROR
EXT
Encode
Error
Extract
FALLBACK
FEATURE
FLOAT
Feed
Figure
Find
FinishDeviceComputation
FloatToHalf
For
GT
Gather
Get
GetBlob
GetSingleArgument
Given
GivenTensorIntFill
HalfToFloat
HasSingleArgumentOfType
HashMap
HashSet
Heuristic
However
ID
IDs
INFO
INT
IR
If
In
Inference
Input
InputsAndConvertToFp
InputsToFp
IsType
LOG
LayerNorm
MAX
Make
MakeArgument
Mapping
Might
Model
ModelProto
Mutable
NAMESPACE
NB
Need
NetDef
Note
Number
OF
ONNX
ONNXIFI
Onnx
OnnxBackendID
OnnxCaffe
OnnxExporter
OnnxExtraTypeProto
OnnxModelProto
OnnxTypeProto
OnnxValueInfoProto
Onnxifi
OnnxifiLibrary
OnnxifiOp
OnnxifiOptionHelper
OnnxifiTransformer
OnnxifiTransformerOptions
OnnxinitOnnxifiLibrary
Op
OpSchema
OpSchemaRegistry
OpToOnnxNodes
OperatorDef
Ops
OptimizeForBackend
Options
Otherwise
Partition
PartitionInfo
Pass
Passing
Pointer
Populate
Predict
Proto
Query
Remove
RemoveLast
Reshape
Resize
Rewrite
Rule
RunNetOnce
SSA
STATUS
SUCCESS
Schema
Second
Self
SerializeToString
Set
ShapeInfo
ShapeInfoMap
Since
Skipping
Sparse
SparseLengthsSum
SparseLengthsSumFused
SparseLengthsSumSparse
SparseLengthsSumSparseLookup
SparseLengthsWeighted
SparseLengthsWeightedSum
SparseLengthsWeightedSumFused
Split
StartsWith
String
SubnetToOnnxifiOpViaC
SubnetToOnnxifiOpViaOnnx
Swap
SwitchToDevice
THROW
TO
TODO
TYPE
Tell
Tensor
TensorBoundShape
TensorProto
TensorShape
Tensors
The
This
Tie
Transform
TransformViaC
TransformViaOnnx
Try
TypeMeta
TypeProto
TypeToOnnxType
UINT
Unroll
Unsupported
Using
VERSION
VLOG
ValueInfoProto
Version
WARNING
We
Weighted
Whether
Workspace
WriteProtoToTextFile
addShapeToNet
annotateOpIndex
applyFilteringRules
blocklistCpuPartition
buildOnnxifiOp
canPassOutputShapeHintsPerBs
collectInputsAndOutputs
composeResultNet
convertToValueInfo
dumpNet
enforceFp
extractPartitionInfo
fetchInputsToIfOpsSubnet
fillModelInfo
getBackendId
getBlob
getDimType
getModelId
getWeightsAndInputs
inferShape
inferShapes
kBridgeTensorSuffix
kBufferSize
kInitializers
kModelId
kNetPos
kRealBatchSizeBlob
mergeFp
onnxBackendID
onnxExtensionFunctionPointer
onnxGetBackendCompatibility
onnxGetBackendIDs
onnxGetBackendInfo
onnxGetExtensionFunctionAddress
onnxGetOptionFunction
onnxGetOptionFunctionPointer
onnxReleaseBackendID
onnxSetOptionFunction
onnxSetOptionFunctionPointer
onnxStatus
optionName
optionValue
optionValueLength
seenExternalInputs
seenInputsForShapeArgs
ssaRewriteAndMapNames
ssaRewritten
stDimSize
stripShapeInfoMap
supportOpC
supportOpOnnx
tieGatherAndSparseLengthsWeightedSumOps
wrapShapeInfoIntoQTensorProto
wrapShapeInfoIntoTensorProto
FROM
FUNC
If
NNModule
OPT
OptimizationPass
OptimizationPassRegistry
OptimizationPassTrait
PASS
REGISTER
Self
This
U
Workspace
WorkspaceOptimizationPass
WorkspaceOptimizationPassRegistry
You
Ambiguous
Annot
Annotation
Caffe
Convert
Declare
DeviceOption
DeviceOptions
Export
HashMap
Helpers
NNGraph
NNModule
Names
NetDef
NetDefs
NeuralNetOperator
NodeRef
Please
String
Tensor
This
Throws
U
Unused
You
addBlobDeviceOptions
blobMap
convertToNNModule
createEdge
createNode
dataFlow
declareNode
declareNodes
deleteNode
deviceOption
exportNode
exportNodes
getInputs
getMutableAnnotation
getName
getOrAddCaffe
getOutputs
injectDataEdgeIndicators
inputNode
outputNode
setDeviceOption
NNModule
NNPACK
NetDef
Option
Proto
U
Workspace
addNNPACK
convertToCaffe
convertToNNModule
fuseConvBN
fuseNNPACKConvRelu
graphOptimzations
workspaceOptimizations
Absorb
AddConv
Adding
BackendCuttingTest
BigOpt
Concat
CopyIn
CopyOut
EXPECT
MyConv
MyRelu
NetDef
OperatorDef
OptimizeForBackend
Random
Relu
StartsWith
Supports
Transform
W
Y
convergedPaths
skipPath
ClipRangesGatherSigridHash
ClipRangesGatherSigridHashConverter
ClipRangesGatherSigridHashV
Converter
CopyFrom
EXPECT
FALSE
MakeArgument
OperatorDef
TRUE
convertToNeuralNetOperator
getHashIntoInt
nnDef
pNNDef
BatchOneHot
CONT
Cast
CastedBatchOneHot
FuseCastBatchOneHot
GraphMatcher
H
NNModule
NOM
NQL
OR
R
REQUIRE
This
U
Unable
dataFlow
fuseCastBatchOneHot
getMatcher
getMatches
getProducer
getTo
initFromString
replaceSubgraphWithOperator
CONT
DeadCodeElim
Iteratively
NNModule
NOM
NeuralNetOperator
No
OR
REQUIRE
U
dataFlow
deadCodeElim
deleteNode
getMutableNodes
getOutputs
hasConsumer
isUsed
Adding
Annotation
Caffe
Cannot
Check
Const
Continue
Convert
ConvertToC
CopyFrom
Data
Delete
Deleting
DetectBoundaryReferences
DumpGraph
ERROR
Explore
Find
Generate
GetInfo
Group
GroupAnnotation
HashMap
HashSet
INFO
Initialize
Input
Kahn
Keeping
Khan
Known
LOG
NNGraph
NNModule
NNOp
Net
NetDef
NeuralNetData
NeuralNetOperator
Node
NodeRef
Nodes
Note
Op
OperatorDef
Option
Precondition
Proto
Prune
PruneUnrefereredNodes
Removing
ReplaceSubgraph
Self
ShowNode
String
THROW
Tensor
This
Topological
Transform
TransformSubgraph
U
VLOG
VisitorContext
We
convertToCaffe
convertToDotString
convertToNNModule
convertToNeuralNetOperator
createEdge
createNode
dataFlow
deleteNode
getAnnotation
getConsumers
getDevice
getInEdges
getMutableNodes
getName
getOperatorDef
getOutEdges
getVersion
hasConsumer
hasProducer
labelMap
resetData
Add
AddArgument
Annote
ArgumentHelper
BackendTransformOptions
BackendTransformerBase
BackendTransformerBaseTrait
Blobs
Bound
BoundShapeInferencerRegistry
BoundShapeSpec
C
CopyFrom
Create
Default
Do
Dump
Enable
Get
GetBlob
GetSingleArgument
HasArgument
HasBlob
HashMap
HashSet
ID
If
InferBoundShapeAndType
Input
Minimum
NetDef
Only
Populate
QTensor
QTensorProto
Quantized
SSA
Self
ShapeInfo
ShapeInfoMap
Since
SsaRewrite
String
TensorProto
TensorShape
This
Workspace
Wrap
WriteProtoToTextFile
addShapeToNet
annotateOpIndex
dimType
dimTypeIsSet
getDimType
getShapeInfoFromBlob
kModelId
kNetPos
wrapShapeInfoIntoQTensorProto
wrapShapeInfoIntoTensorProto
ADD
ARG
Annotation
Argument
CPU
Caffe
Conv
DeviceTest
EXPECT
FALSE
Generic
GenericOperator
Ignore
InsertCopies
NCHW
NNGraph
NOM
NetDef
NeuralNetOperator
NodeRef
OPENCL
OR
OperatorDef
PROTO
Proto
REQUIRE
RET
Relu
W
convertToCaffe
convertToNNModule
createNode
dataFlow
getDeviceType
getMutableAnnotation
getMutableNodes
insertCopies
setDeviceType
BadDiamond
Basic
Caffe
Check
Concat
Create
Diamond
EXPECT
FALSE
FC
Flatten
Foo
GraphMatcher
HashMap
Manually
MatchSingleNode
NNGraph
NQL
NodeRef
R
Relu
StarInputs
StarOutputs
String
Sum
SyntaxError
TRUE
Tensor
TensorsNameDeduplication
The
ToNQL
We
convertToNQLString
createEdge
createNode
findSubgraph
genTensors
getMatchMap
gmMismatch
initFromString
matchMap
reluInput
reluOutput
All
Axis
CMP
Cannot
ConcatAddMulReplaceNaNClip
ConcatAddMulReplaceNaNClipOp
CopyMatrix
Expect
GetSingleArgument
HasArgument
INT
Input
InputSize
LT
MAX
NaN
OPERATOR
OQ
Operator
OperatorDef
OperatorStorage
Output
Self
Tensor
The
Workspace
Declare
DeclareConverter
Export
ExportConverter
ASTExpr
ASTGraph
ASTStmt
Drop
Function
GRAPH
LHS
NULL
Option
String
Var
isCall
isCallFlag
starInputsFlag
ADD
ARG
Argument
Conv
Convolution
MobileTest
NCHW
NNPACK
NetDef
OperatorDef
Proto
Relu
W
addNNPACK
convertToCaffe
convertToNNModule
ActivationT
Annotation
Application
Assume
BN
BatchNormalization
Blob
BlobGetMutableTensor
CHECK
CHW
CONT
CPU
Caffe
Check
Conv
CreateBlob
DATA
Data
DataType
EXPOSE
Float
Functor
FuseConvBN
Generic
Get
GetBlob
Given
HWC
HasBlob
In
Invalid
M
NNGraph
NNModule
NOM
NOTNULL
Neural
NeuralNetData
NodeRef
OR
OperationT
REQUIRE
Ready
Resize
TENSOR
Tensor
TensorCPU
The
U
W
W\frac
We
Workspace
biasBN
biasBNData
biasConv
biasConvData
bnInputs
bnNode
bnOutput
bnOutputs
chwDim
convBN
convBiasName
convBiasNode
convBiasTensor
convInputs
convName
convNode
convOrder
createEdge
createNode
dataFlow
dataIterator
deleteNode
filterData
filterTensor
fuseConvBN
fuseConvBNHelper
getConsumers
getEpsilon
getInputs
getMutableAnnotation
getName
getOperatorDef
getOutputs
meanData
replaceNode
sW
scaleData
setType
varianceData
A
Annotation
AnnotationKind
CPU
Caffe
Default
Device
DeviceOption
DeviceType
DeviceTypeProto
Distributed
No
NodeRef
OpDef
OpDefExists
OperatorDef
PROTO
ParallelizationScheme
Self
String
U
Use
devOpt
getKind
hasDeviceOption
opDef
setDeviceOption
setOperatorDef
Add
AddConverter
ArgumentHelper
BatchGather
BatchGatherConverter
BatchMatMul
BatchMatMulConverter
Box
Cast
CastConverter
ClipRanges
ClipRangesConverter
ClipRangesGatherSigridHash
ClipRangesGatherSigridHashConverter
ClipRangesGatherSigridHashV
ConcatAddMulReplaceNaNClip
ConcatAddMulReplaceNaNClipConverter
Converter
CopyFrom
Does
GetCastDataType
GetRepeatedArgument
GetSingleArgument
HasArgument
Invalid
MakeArgument
Mul
MulConverter
NeuralNetOperator
OperatorDef
ReplaceNaN
ReplaceNaNConverter
SigridHash
SigridHashConverter
Slice
SliceConverter
argMap
clipRanges
getArgumentsFromOperator
getClipMax
getClipMin
getDeviceOption
getEnds
getFeatureIndices
getHashIntoInt
getMaxLength
getMaxLengths
getMaxValue
getMaxValues
getSalt
getSalts
getStarts
hashIntoInt
maxValue
nnOp
setBroadcast
setClipMin
setEnds
setFeatureIndices
setHashIntoInt
setMaxLength
setMaxLengths
setMaxValue
setMaxValues
setSalt
setSalts
setStarts
setTo
setTransA
setTransB
setValue
sigridHash
BATCH
BOOL
BYTE
Blob
BoundShapeInferencer
C
COLLISION
CONSTANT
Cannot
Change
Construct
Create
DEFAULT
DOUBLE
DataType
Default
DimType
Eq
ExternalTensorFunctionsBaseRegistry
Extract
FEATURE
FLOAT
For
GE
GT
Generates
GetTensorShapeOfBlob
HASH
HashMap
INT
Id
If
In
Int
Kept
LoadInfoOfBlob
LoadInt
MAX
MOBILE
Need
OF
Old
Option
PartialEq
QShapeInfo
SEQ
STRING
Self
SerializeAsString
Set
ShapeInfo
ShapeInfoMap
String
THROW
TODO
TensorBoundShape
TensorBoundShapes
TensorCPU
TensorInfoOfBlob
TensorProto
TensorShape
TypeMeta
UINT
UNKNOWN
We
ZERO
changeTensorBoundShapes
constructShapeInfoWithDefaultDimType
defaultFirstDimType
dimType
getDimType
isNumber
isQuantized
modifyTensorShapeDimSize
setDimType
tensorBoundShapes
toLower
toTensorProtoDataType
ALGORITHM
Add
AddRelu
AffineChannel
Annotation
Assume
AveragePool
BN
BatchNormalization
BatchPermutation
Blob
CHW
CONV
Caffe
Can
Cannot
Caution
Check
Conv
ConvFusion
ConvRelu
ConvSum
ConvSumRelu
ConvTranspose
Data
Dequantize
DeviceTypeProto
ERROR
FC
FP
FUSION
Find
For
Fuser
Fusers
Get
GetBlob
GetMutable
HWC
HasBlob
Here
IDEEP
INFO
INT
If
In
Int
Invalid
IsType
It
LOG
LT
M
MAX
MaxPool
NCHW
NHWC
NNGraph
NNModule
NOT
NeuralNetData
NeuralNetOperator
NodeRef
Not
On
Only
Op
Operator
OperatorDef
Ops
Option
PROTO
Pre
Python
Quantize
RELU
ReLU
Ready
Relu
Reset
RoIAlign
SUM
Sigmoid
Softmax
StopGradient
String
Sum
SumRelu
THROW
Tensor
The
To
U
Unsupport
UpsampleNearest
WARNING
WINOGRAD
We
When
Workspace
Y
allNodes
argName
biasBNOrAffCh
biasBNOrAffChData
biasConv
biasConvData
biasConvTensor
bnOrAffChInputs
bnOrAffChNode
bnOrAffChOutput
checkInputs
checkNode
checkOutputs
chwDim
convInput
convInputs
convNode
convOp
convOutput
convTranspose
createEdge
createNode
dataFlow
dataIterator
dataType
deleteNode
dstOp
expectedDesc
filterBlob
filterData
filterTensor
getAnnotation
getAxisW
getBlob
getConsumers
getDilations
getEpsilon
getGroup
getInEdges
getInputs
getMutableAnnotation
getMutableNodes
getMutableOpDef
getMutableOperatorDef
getMutableTensor
getName
getOpDef
getOperatorDef
getOutputs
getPads
getProducer
getStrides
hasInputs
hasSingleOutputAndConsumer
iDEEP
initValue
inputName
isBN
isConvFusion
isOnIdeepDevice
isOpType
meanData
moveOpArg
newFilter
newInput
newInputTensor
newOutput
newOutputName
newOutputTensor
nnOp
nodeRef
numInputs
opArgs
opDef
opNode
osNode
outputName
poolNode
preConvertFiltersFormat
preNode
preOp
predOp
removeArg
replaceNode
resetConvForFusion
scaleData
seqNode
seqOp
setPoolingInferenceMode
setTrainingMode
srcOp
stopGradInput
stopGradOutput
sumInputX
sumInputs
sumNode
sumOutput
typeName
varianceData
Add
BatchGather
BatchMatMul
BitRowwise
BitRowwiseQuantFloatMulLengthsSumElim
BitRowwiseQuantizedToFloat
CONT
Check
Clip
Concat
ConcatAddMulNaNClipElim
ConcatAddMulReplaceNaNClip
ConcatBatchMatMulBatchGatherOp
ConcatElim
D
FALSE
Figure
First
Flatten
Fused
Gather
GatherFuse
GraphMatcher
Handle
INFO
If
Iterate
LOG
LengthsSum
Mul
NNGraph
NNMatchGraph
NNModule
NOM
NQL
NodeRef
OR
R
REQUIRE
RET
ReplaceNaN
Set
Skip
SparseLengthsWeightedSumFused
SubgraphMatchResultType
TODO
Tensor
The
This
U
Unable
Various
batchGatherNode
batchGatherNodeOutputs
concatAddMulNaNClipElim
concatElim
concatNode
createEdge
createNode
dataFlow
deleteNodes
fusedNode
gatherFuse
getAddAxis
getAxis
getBroadcast
getInputs
getMatchNodeMap
getMatchedSubgraph
getMatcher
getMatches
getMax
getMin
getName
getNodes
getOutputs
getProducer
getTransA
getTransB
getValue
hasSingleOutputAndConsumer
hasUniqueConsumer
initFromString
matchBatchGather
matchBatchMatmul
matchBmmOutput
matchConcat
matchConcatInputs
matchConcatOutput
matchExternalTensorNode
matchFlatten
matchFlattenOutput
matchIndices
matchResult
newOutput
nodeRef
replaceInEdges
replaceOutEdges
replaceSubgraph
replaceSubgraphWithOperator
starCount
A
API
Annotation
AnnotationKind
Default
Device
NNGraph
NNModule
NetDef
NeuralNetOperator
NodeRef
Onnx
OnnxAnnotation
OpDef
OperatorDef
Self
String
TORCH
Use
blobMapOut
convertToNNModule
convertToOnnxProto
convertToOperatorDef
getKind
opDef
setOperatorDef
Basic
Conv
Converter
Declare
EXPECT
Ensure
Export
ExternalInputs
ExternalOutputs
Fake
InjectDataEdgeIndicators
Inserted
NCHW
NE
NetDef
NetMutator
NeverSeen
Proto
Relu
Remove
Slice
SpecializeConverter
UnknownType
W
Y
Z
addArgument
convertToCaffe
convertToNNModule
externalInputs
externalOutputs
fakeNet
injectDataEdgeIndicators
newOp
removeDataEdgeIndicators
setDeviceOptionName
Annotation
Caffe
Converter
Declare
DeclareExport
DeviceOption
Distributed
EXPECT
Export
FAKE
Fake
InjectDataEdgeIndicators
InsertDeviceOptions
InsertDeviceOptionsFailureCase
Inserted
Key
Main
NE
NetDef
NeuralNetOperator
Only
OperatorDef
OverloadedConvertToNNModule
OverloadedConvertToNNModuleFailure
Proto
Remove
Reset
String
THROW
Tensor
This
W
We
What
Y
Z
addBlobDeviceOptions
convertToCaffe
convertToNNModule
declareNode
exportNode
fakeNet
getAnnotation
getDeviceOption
getName
getOutputs
injectDataEdgeIndicators
inputNode
removeDataEdgeIndicators
A
AddArgument
AdjustBatch
ArgumentHelper
Attach
BackendTransformerBase
Before
C
Cannot
Carrying
Clean
Cleanup
Clear
Concat
Copy
CopyFrom
Enable
Example
FLAGS
GetSingleArgument
HashMap
HashSet
Ignoring
In
LOG
Merge
Minimum
Mul
Name
NetDef
ONNX
ONNXIFI
Onnxifi
OnnxifiTransformer
OnnxifiTransformerOptions
OperatorDef
Option
Parse
ParseBlockListOps
ParseNetPositionList
RemoveBlob
Reshape
Shape
ShapeInfoMap
SparseLengthsSum
SparseLengthsSumSparse
Split
String
THROW
Tanh
TensorObserver
The
This
Timeout
WARNING
We
When
Whether
Workspace
annotateOpIndex
kNetPos
parseShapeInfoMapFromString
splitSparseLengthsSumSparse
AUTO
AddNNPACK
Annotation
CONT
Caffe
Check
Conv
DConv
FP
FT
FuseNNPACKConvRelu
Kx
NCHW
NNGraph
NNLayout
NNModule
NNPACK
NOM
NeuralNetOperator
NodeRef
Now
OR
Option
PRECOMPUTE
REQUIRE
Relu
Requires
Skip
String
U
W
WINOGRAD
We
addNNPACK
dataFlow
fuseActivation
fuseNNPACKConvRelu
getAnnotation
getInEdges
getKernelShape
getLayout
getMutableAnnotation
getMutableNodes
getMutableOperatorDef
getOperatorDef
getStrides
isNNPACKConvReluEfficient
kernelShape
nnOp
validTransformCandidate
xK
CONT
Check
EdgeRef
Finally
First
NNGraph
NNModule
NOM
NeuralNetData
NeuralNetOperator
NodeRef
OR
REQUIRE
Rectify
Second
SubgraphType
Tensor
Third
U
We
addOutEdge
binaryMatch
brokenEdge
changedEdges
consumerOp
copyFromFn
copyFromNode
copyFromOp
copyNode
copyOp
copyToFn
createEdge
createNode
dataFlow
deleteNode
getConsumers
getEdge
getInputEdges
getInputs
getKind
getName
getNodes
getOutputEdges
getOutputs
getProducer
hasInputs
hasNode
hasProducer
inputTensorEdges
newInput
newOutput
oldInputs
outputTensorEdges
producerOp
removeInEdge
removeOutEdge
setHead
setTail
A
ASTExpr
ASTGraph
ASTStmt
Attempt
Cleanup
Could
Criteria
Currently
DF
Data
Different
Do
Each
Fill
Foo
For
Given
Going
GraphMatcher
HashMap
Helper
IR
Index
Initialize
It
Main
Maps
MatchGraph
MatchPredicate
MatchedSubgraph
NNGraph
NQL
NeuralNetData
NeuralNetOperator
Node
NodeRef
Nodes
Op
Option
Order
Output
Provides
RawMutex
Replace
Return
Returns
STR
See
Self
Special
String
Subgraph
SubgraphType
THROW
TODO
Temporary
TestMatchGraph
TestMatchPredicate
The
This
Try
U
We
`getMatches`
callMap
computeDedupRenameMap
convertToNQLString
createEdge
createNode
deallocTokenStrings
dedupCounter
defOp
doesMatch
genMatcherFromASTExpr
genMatcherFromASTGraph
genMatcherFromASTStmt
genMatcherFromIRFile
genMatcherFromIRStr
getInputs
getMatchNodeMap
getMatchedSubgraph
getMatcherGraph?
getMutableNodes
getNQLStringForBlob
getName
getNameForBlob
getNodeName
getNodes
getProducer
hasProducer
inputTensor
insertTemp
isCall
isMatch
isSubgraphMatch
matchGraph
matchGraphRootNode
matchMap
newName
nodeLabel
nodeRef
nonTerminal
parseFile
parseString
renameMap
sccNum
setDebugString
starCount
starInputs
subgraphMatcherMap
syntaxIsValid
takenNames
testMatchPredicate
tokenVectors
topoMatch
varMap
Add
Basic
BasicNet
BatchGather
BatchMatMul
BitRowwiseQuantFloatMulLengthsSumElim
BitRowwiseQuantized
BitRowwiseQuantizedToFloat
Blob
BlobGetMutableTensor
CPU
Clip
Clone
Concat
ConcatAddMulNaNClipElim
ConcatElim
Copy
CreateBlob
CreateOperatorDef
Data
EXPECT
Ensure
Fill
Flatten
FloatToFused
Fout
Fused
Gather
GetBlob
GetRaw
Gout
Idx
LT
Len
LengthsSum
Min
Mout
Mul
NetDef
NetMutator
NoFuse
OperatorDef
Out
ProdNet
Proto
ReadProtoFromFile
ReinitializeTensor
RemoveBlob
ReplaceNaN
Run
RunNetOnce
RunOperatorOnce
TensorFiller
Test
TestDataRandomFiller
Workspace
addArgument
assertTensorEquals
concatAddMulNaNClipElim
concatElim
convertToCaffe
convertToNNModule
fillInputToWorkspace
gatherFuse
getTensor
newOp
outAfter
outBefore
Add
BitRowwiseQuantizedToFloat
Build
CONSTANT
CPU
Cannot
CopyFrom
CreateOperatorDef
DataType
Dim
DimType
Dims
FLOAT
FP
FloatToHalf
Fused
GT
HalfToFloat
HashSet
Heuristic
If
Indicating
MakeArgument
NetDef
Not
OperatorDef
Optimization
SUFFIX
ShapeInfoMap
String
Swap
TensorBoundShape
TensorProto
Tile
isFp
kFP
kTILE
setDimType
setShape
CopyFrom
Extract
FC
Get
GetBlob
Hence
Int
IsType
It
LOG
MakeArgument
NetDef
ParamBlob
QuantParamsBlob
Quantize
Remove
RemoveLast
Skip
WARNING
We
Workspace
Y
argSet
lastPos
paramName
BitRowwise
BitRowwiseSparse
BlobGetMutableTensor
Compressed
CreateBlob
Data
EXPECT
Idx
Lengths
NetDef
NetMutator
Out
SparseLengths
SparseLengthsSum
SparseLengthsSumFused
SparseLengthsSumSparseLookup
SparseLengthsWeightedSum
SparseLengthsWeightedSumFused
String
Sum
Weight
WeightedSum
Workspace
createTest
newOp
splitSparseLengthsSumSparse
A
Acc
AccFP
Add
AddFakeFp
ArgumentHelper
Attemping
Attempting
BatchMatMul
BatchMatMulFP
BitRowwise
BitRowwiseFakeFP
Clip
CopyFrom
Dequantize
DequantizeNNPI
Div
DivFakeFp
FC
FCAcc
FCFakeAcc
FLAGS
Fake
FbFCPacked
FoldLayerNorm
FoldLayerNormQuant
FoldSwish
FoldTanhQuant
Fp
FuseOps
Fused
Fusing
Fusion
GetSingleArgument
HashMap
INFO
Int
LOG
LayerNorm
LayerNormFakeFP
LayerNormInt
LengthsSum
LengthsSumFakeFp
Logit
LogitFakeFp
MakeArgument
Mapping
Mul
MulFakeFp
NNPI
NetDef
ONNXIFI
OpConversionMap
OpMapping
OperatorDef
Option
ParseBlockListOps
ParseNetPositionList
Quant
Quantize
QuantizeFakeNNPI
QuantizeNNPI
Relu
ReluFakeFp
Running
Sigmoid
SigmoidFakeFp
SparseLengthsMean
SparseLengthsMeanFakeFP
SparseLengthsMeanFused
SparseLengthsSum
SparseLengthsSumFakeFP
SparseLengthsSumFused
SparseLengthsWeightedSum
SparseLengthsWeightedSumFakeFP
SparseLengthsWeightedSumFused
SpatialBN
SpatialBNFakeFp
Sqr
SqrFakeFp
String
Sub
SubFakeFp
Sum
SumFakeFp
Swish
SwishFakeFp
SwishFakeInt
TODO
Tanh
TanhFakeFp
TanhQuantFakeFp
Transform
Use
We
Whether
Y
deqOutput
fakeFp
findMutableOperatorByInput
getFakeFp
kFakeFp
layernormNetPos
quantNetPos
quantOp
swishOp
tanhOutput
ASSERT
Argument
ArgumentHelper
BATCH
BitRowwiseQuantizedToFloat
CHECK
CONSTANT
CPU
CopyFrom
CreateOperatorDef
DataType
Didn
DimType
EXPECT
FLOAT
FloatToHalf
Fused
GetSingleArgument
HalfToFloat
HasArgument
InBatchBroadcast
MakeArgument
NetDef
Option
PROTO
ShapeInfo
ShapeInfoMap
Shapes
TensorBoundShape
TensorProto
TensorShape
Tile
UINT
checkNet
checkShapeInfo
getDimType
inBatchBroadcast
makeTensorInfo
setDimType
BasicElim
BasicNoElim
Create
DeadCodeElim
EXPECT
Fake
NetDef
OperatorDef
OptimizationPassRegistry
PartiallyUsedNoElim
Proto
Y
Z
convertToCaffe
convertToNNModule
A
AOT
ATTRIBUTE
Adjust
All
Arc
ArgumentHelper
At
BACKEND
BATCH
BLOB
Backend
Based
Blob
BlobIsInt
BlobIsTensorType
BlobToTensorDescriptor
Blobs
BoundShapeInferencerRegistry
BoundShapeSpec
Build
C
CONSTANT
CPU
Caffe
Call
Cannot
CopyFrom
Create
DATATYPE
DEFERRED
DESCRIPTOR
DEVICE
Data
DataType
Default
Destroy
DimContainer
DimType
Drop
ENABLE
ERROR
EVENT
EXT
Else
Encode
ExternalTensorDescriptor
ExternalTensorFunctionsBaseRegistry
Extra
Extract
FALLBACK
FATAL
FCDNNLowPPackedWeightBlob
FENCE
FLOAT
Fatal
For
From
GE
GRAPH
GT
Get
GetBlob
GetRepeatedArgument
GetSingleArgument
Glow
Half
HasBlob
HashMap
Helper
ID
INFO
INT
INTERNAL
INVALID
Id
If
In
Indicate
InferBoundShapeAndType
Inference
Initialization
Initialize
Input
InputIsType
InputSize
Int
IntArrayRef
IsType
It
LOCATION
LOG
LT
MAPPED
MAX
MEMORY
MISMATCHING
MOBILE
MODEL
Make
Mapping
Maybe
Memory
NAME
NO
NONE
NOT
NetDef
Normal
Null
ONNX
ONNXIFI
OPERATOR
OPTIMIZATION
OnnxBackend
OnnxBackendGraphInfo
OnnxBackendGraphMap
OnnxBackendID
OnnxEvent
OnnxEventState
OnnxGraph
OnnxMemoryFenceV
OnnxSharedPtrBackendGraphInfo
OnnxStatus
OnnxTensorDescriptorV
OnnxTraceEventList
OnnxfiBackendSystemError
OnnxgetOnnxBackendGraphMap
Onnxifi
OnnxifiLibrary
OnnxifiOp
OnnxifiTypeToDataType
OnnxinitOnnxifiLibrary
Operator
OperatorDef
OperatorStorage
Otherwise
Output
OutputReshapeInfo
OutputSize
POINTER
PROPERTY
PROTOBUF
ParseProtoFromLargeString
Populate
Possibly
Provides
QTensorProto
READER
RESOURCES
Reason
ReinitializeTensor
Release
Resize
SHAPE
SIGNALLED
SIZE
STATE
STATUS
STRING
SUCCESS
SYNCHRONIZATION
SYSTEM
Second
Self
Serialized
Set
Setup
SetupExternalTensorDescriptor
ShapeInfo
ShrinkTo
Since
Slice
SliceImpl
SmallVec
SmallVector
String
Subsequent
TAG
TENSOR
THROW
TO
TYPE
Tensor
TensorBoundShape
TensorCPU
TensorCPUType
TensorInfo
TensorProto
TensorShape
The
This
TypeMeta
TypeName
U
UINT
UNAVAILABLE
UNDEFINED
UNIDENTIFIED
UNSUPPORTED
Unable
Unfulfilled
Unsupported
Used
V
VERSION
WARNING
We
When
Whether
Workspace
adjustOutputBatchSizes
adjustQuantizedOffset
adjustQuantizedOffsetImpl
auxPropertiesListAOT
buildBackendAndGraph
buildInitializationList
buildPropertyList
copyDescriptor
currentIndex
dataType
eventState
eventStatus
extractOutputBatchSizes
fillOutputReshapeInfo
getExtFunctionPointers
getOnnxifiDataType
initOutputReshapeInfo
isOffline
mapOnnxStatusToString
memoryType
messageLength
numEvents
onnxBackend
onnxBackendID
onnxDesciptor
onnxEventState
onnxExtensionFunctionPointer
onnxGetBackendIDs
onnxGetExtensionFunctionAddress
onnxGraph
onnxInitBackend
onnxInitEvent
onnxInitGraph
onnxMemoryFenceV
onnxPointer
onnxReleaseBackendID
onnxReleaseEvent
onnxReleaseTraceEventsFunction
onnxReleaseTraceEventsPointer
onnxRunGraph
onnxSetGraphIO
onnxSetIOAndRunGraph
onnxSetIOAndRunGraphFunction
onnxSetIOAndRunGraphPointer
onnxSignalEvent
onnxStatus
onnxTensorDescriptorV
onnxTraceEventList
onnxWaitEvent
onnxWaitEventForFunction
onnxWaitEventForPointer
quantizationAxis
quantizationParams
setInputTensorDescriptorTypeAndBuffer
setOutputShapeAndType
setOutputTensorDescriptorTypeAndBuffer
A
Annotation
Argument
Attempting
AveragePool
AveragePoolConverter
BatchNormalization
BatchNormalizationConverter
Be
Because
Box
CFG
Caffe
Cannot
Clear
Clip
ClipConverter
Concat
ConcatConverter
Control
Conv
ConvConverter
ConvTranspose
ConvTransposeConverter
Converter
ConverterRegistry
CopyFrom
Couldn
Create
DFG
Declare
Default
DeleteSubrange
DeviceOption
Does
ERROR
Export
FC
FCConverter
First
Flatten
FlattenConverter
For
Generic
GenericOperator
Has
HashMap
HashSet
If
In
Ingest
Invalid
LOG
MaxPool
MaxPoolConverter
Maximally
NCHW
NHWC
NNCFGraph
NNGraph
NNLayout
NNModule
NetDef
Nets
NeuralNetData
NeuralNetOperator
NodeRef
NodeRefs
Note
OperatorDef
Ops
Option
Optionally
Otherwise
Pass
Proto
Relu
ReluConverter
RepeatedPtrField
Reverse
Save
Simply
SpatialBN
String
Sum
SumConverter
SwapElements
THROW
TODO
Tensor
The
Then
There
U
Undefined
Use
WARNING
We
argMap
bbNode
blobMap
coalesceInsertedDataDependencies
controlFlow
convertToCaffe
convertToNeuralNetOperator
convertToOperatorDef
createEdge
createNamedFunction
createNode
currExternal
currentBasicBlock
dataFlow
externalInputNames
getAnnotation
getArgumentsFromOperator
getDeviceType
getDilations
getGroup
getInEdges
getInstructions
getKernelShape
getLayout
getMutableAnnotation
getMutableNodes
getName
getOperatorDef
getOutEdges
getPads
getStrides
inEdge
inputName
instrNode
kernelH
kernelShape
kernelW
mergeExternalTensors
mutableData
newExternal
newExternalInputs
newExternalOutputs
nnOp
oldExternal
oldExternalInputs
oldExternalOutputs
oldNet
opNode
opNodeVec
outEdge
outputName
predictNet
pushInstructionNode
pushOpToFront
resetData
setAddAxis
setAnnotation
setAxis
setAxisW
setDevice
setDeviceType
setDilations
setGroup
setLayout
setOperatorDef
setPads
setStrides
tensorName
tensorNode
Add
AddArgument
And
Apply
Argument
ArgumentHelper
Asssume
BackendTransformOptions
BackendTransformerBase
BatchGather
BatchMatMul
BitRowwise
BitRowwiseQuantizedToFloat
C
Cast
Caught
Clean
Clear
Clip
Concat
Copy
CopyFrom
Cutting
DotProduct
ERROR
EnsureCPUOutput
ExpandDims
FC
FCTransposed
FbFCPacked
Flatten
Frontend
Fused
Get
GetSingleArgument
Given
HashSet
Helper
INFO
If
Indices
LOG
Logit
MatMul
Memonger
Model
Mul
NetDef
OperatorDef
OptimizeForBackend
Options
Predict
Record
Relu
Remove
ReplaceNaN
Reshape
SEQ
Save
Self
ShapeInfoMap
Sigmoid
Skipping
Slice
Softmax
SparseLengthSum
SparseLengthWeightedSum
SparseLengthsSum
SparseLengthsSumFused
SparseLengthsWeightedSum
SparseLengthsWeightedSumFused
Split
String
Sum
Swap
TODO
TVM
TVMC
TVMJit
TVMJitOPs
TVMJitOp
Tanh
The
Therefore
This
Track
Transpose
TvmTransformOptions
TvmTransformer
UnPackRecords
User
We
Whether
Workspace
applyTvmTransform
buildTvmOp
cleanUpPredictNet
dumpNet
getModelId
getSupportedOps
inferShapes
kNetPos
wrapShapeInfoIntoTensorProto
