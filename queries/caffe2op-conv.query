hello! 

I am writing a rust crate called caffe2op-conv. 

It defines a mathematical operator used in DSP
and machine learning computations.

I would like you to help me write a rust crate
description for it.

Please write the description in the followin format:

<short description tag used in the crate header>
<double newline>
<longer, in depth description and mathematical analysis>
<END>

Below are listed some tokens from this crate. 

Please describe the mathematical ideas
identified by this information alongside the
relevant mathematical equations.

thanks!

please format your response in the Markdown file format.

here are the tokens:
run_on_device_with_order_nchw
run_on_device_with_order_nhwc
ConvGradientOp
ConvOp
conv_doc_generator
conv_op_example
cost_inference_function
doc_fn
inherit_onnx_schema
register_cpu_operator
tensor_inference_function
reinterleave_multithreaded
reinterleave_rows
run_on_device_with_order_nchw
run_on_device_with_order_nhwc
run_tile_contiguous
ConvTransposeUnpoolBase
adj_h
adj_w
compute_size_and_pad
kernel_h
kernel_w
pad_b
pad_l
pad_r
pad_t
run_on_device
run_on_device_with_orderNCHW
run_on_device_with_orderNHWC
stride_h
stride_w
AlgorithmsCache
get_algorithm
EigenConvOp
register_cpu_operator_with_engine
run_on_device_with_orderNHWC
run_on_device_with_order_nchw
CudnnConvTransposeGradientOp
CudnnConvTransposeOp
CudnnConvTransposeOpBase
drop
register_cuda_operator
run_on_device
set_tensor_4ddescriptor_with_group
ConvBwdDataAlgorithmWithCost
ConvBwdFilterAlgorithmWithCost
ConvFwdAlgorithmWithCost
CudnnConvGradientOp
CudnnConvOp
CudnnConvOpBase
do_run_with_type
drop
duplicate_conv_desc
given
register_cudnn_operator
run_on_device
set_conv_desc_compute_type
set_tensor_nd_descriptor_with_group
ConvPoolOpBase
OpSchema
allocate_and_copy
compute_pads
compute_size_and_pad
compute_size_and_pad64
cost_inference_for_conv
dilation_h
dilation_w
get_dims
get_dims_size
has_pad
has_stride
kernel_h
kernel_w
pad_b
pad_l
pad_r
pad_t
run_on_device
run_on_device_with_orderNCHW
run_on_device_with_orderNHWC
set_bias_multiplier
set_device_tensor
stride_h
stride_w
tensor_inference_forLC
tensor_inference_for_conv
tensor_inference_for_pool
tensor_inference_for_schema
create_shared_buffer_cpu_context
create_shared_buffer_cuda_context
run_with_shared_buffer_cpu_context
run_with_shared_buffer_cuda_context
ConvTransposeMobile_Test
compare
rand_int
relative_error
AlgorithmsCacheTest_CachesCorrectly
AlgorithmsCacheTest_KeysDifferIfFlagsAreDifferent
AlgorithmsCacheTest_KeysDifferIfOneVectorIsEmpty
ConvTransposeGradientOp
ConvTransposeOp
conv_transpose_op_example
inherit_onnx_schema
register_cpu_operator
register_cuda_operator
GetConvGradient
OpSchema
cost_inference_for_conv_gradient
cost_inference_function
get_gradient_defs
register_cpu_operator
register_gradient
tensor_inference_for_conv_gradient
tensor_inference_function
GetConvTransposeGradient
get_gradient_defs
register_cpu_operator
register_gradient
ConvTransposeMobileOp
register_cpu_operator_with_engine
computation
run1x_1conv_on_device_with_orderNCHW
run1x_1conv_on_device_with_orderNHWC
run_on_device_with_orderNCHW
run_on_device_with_orderNHWC
run_on_device_with_order_nchw
