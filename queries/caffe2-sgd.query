hello! 

I am writing a rust crate called caffe2-sgd. 

It is part of workspace containing the rust
translation of the caffe2 operator library.

I would like you to help me write a rust crate
description for it.

Please write the description in the following format:

<short description tag used in the crate header>
<double newline>
<longer, in depth description and mathematical analysis>
<END>

Please indicate that the crate is in the
process of being translated from C++ to
Rust. It is possible some of the function
bodies are in the process of translation.

Below are listed some tokens from this crate. 

Please describe the mathematical ideas
identified by this information alongside the
relevant mathematical equations in unicode.

thanks!

please format your response in the Markdown file format.

here are the tokens:
YellowFinOp
after_apply
allow_inplace
get_lr_mu
momentum_sgd_update
moving_average
register_cpu_operator
run_on_device
should_not_do_gradient
zero_debias_factor
dot
dot_float_half_float
dot_float_x3
SparseAdagradFusedWithSparseLengthsSumGradientOp
SparseAdagradFusedWithSparseLengthsWeightedSumGradientApproxOp
SparseAdagradFusedWithSparseLengthsWeightedSumGradientOp
adagrad_update_prefetch_inlined
do_run_with_type
enforce_inplace
enforce_one_to_one_inplace
invoke
register_cpu_operator
run_on_device
AdagradOp
RowWiseSparseAdagradOp
SparseAdagradOp
adagrad_update
allow_inplace
as
cost_inference_for_adagrad
cost_inference_for_row_wise_sparse_adagrad
cost_inference_for_sparse_adagrad
cost_inference_function
do_run_with_type
enforce_one_to_one_inplace
register_cpu_operator
register_cpu_operator_with_engine
run_on_device
should_not_do_gradient
AdadeltaOp
SparseAdadeltaOp
adadelta_update
allow_inplace
do_run_with_type
enforce_one_to_one_inplace
register_cpu_operator
run_on_device
should_not_do_gradient
AdamOp
RowWiseSparseAdamOp
SparseAdamOp
adam_compute
adam_update
allow_inplace
default
device_inference_function
do_run_with_type
enforce_inplace
radam_compute
radam_update
register_cpu_operator
run_on_device
should_not_do_gradient
RowWiseCounterOp
do_run_with_type
enforce_one_to_one_inplace
register_cpu_operator
run_on_device
should_not_do_gradient
WeightScaleOp
allow_inplace
device_inference_function
do_run_with_type
do_run_with_type_cuda_context
register_cpu_operator
register_cuda_operator
run_on_device
should_not_do_gradient
weight_scale_update
weight_scale_update_kernel
FP32MomentumSGDUpdateOp
fp32_momentum_sgd_update
run_on_device
MomentumSGDOp
MomentumSGDUpdateOp
SparseMomentumSGDUpdateOp
allow_inplace
do_run_with_type
enforce_inplace
momentum_sgd_update
register_cpu_operator
run_on_device
should_not_do_gradient
tensor_inference_function
FP16MomentumSGDUpdateOp
fp16_momentum_sgd_update
run_on_device
ClipTensorByScalingOp
allow_inplace
register_cpu_operator
run_on_device
should_not_do_gradient
RowWiseAdagradUpdateInlined
RowWiseSparseAdagradFusedWithSparseLengthsSumGradientOp
RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientApproxOp
RowWiseSparseAdagradFusedWithSparseLengthsWeightedSumGradientOp
compute
compute_impl
compute_square_average_inlined
compute_square_average_with_weight_decay_inlined
compute_square_average_with_weight_decay_inlined_f16_weights
do_run_with_type
do_run_with_type_impl
enforce_inplace
enforce_one_to_one_inplace
for
invoke
register_cpu_operator
register_cpu_operator_with_engine
run_on_device
FtrlOp
FtrlParams
SparseFtrlOp
allow_inplace
do_run
enforce_inplace
ftrl_compute
ftrl_update
of
register_cpu_operator
run_on_device
sgn
should_not_do_gradient
LearningRateOp
LearningRateOpFloatCPU
create_learning_rate_functor
device_inference_function
no_gradient
register_cpu_operator
register_cuda_operator
run_on_device
tensor_inference_function
RmsPropOp
allow_inplace
register_cpu_operator
rmsprop_update
run_on_device
should_not_do_gradient
GFtrlOp
GFtrlParams
allow_inplace
gftrl_compute
gftrl_update
register_cpu_operator
run_on_device
should_not_do_gradient
LarsOp
compute_learning_rate
compute_learning_rate_f32_cpucontext
compute_norms
register_cpu_operator
run_on_device
should_not_do_gradient
LearningRateAdaptionOp
allow_inplace
lr_update
no_gradient
register_cpu_operator
run_on_device
SparseStormOp
StormOp
allow_inplace
do_run_with_type
enforce_one_to_one_inplace
register_cpu_operator
run_on_device
should_not_do_gradient
storm_update
SparseWngradOp
WngradOp
allow_inplace
do_run_with_type
enforce_one_to_one_inplace
register_cpu_operator
run_on_device
should_not_do_gradient
wngrad_update
AtomicIterOp
AtomicIterOpStats
IterOp
MutexDeserializer
MutexSerializer
deserialize
enforce_inplace
increment_iter
no_gradient
register_blob_deserializer
register_blob_serializer
register_cpu_operator
register_cuda_operator
register_ideep_operator
run_on_device
serialize
AlternateLearningRate
CompositeCosineLearningRate
CompositeCyclicalLearningRate
CompositeLearningRate
CompositeLearningRateItem
ConstantThenLinearWarmupLearningRate
ConstantWarmupLearningRate
CosineLearningRate
CyclicalLearningRate
ExpLearningRate
FixedLearningRate
GateLearningRate
HillLearningRate
InvLearningRate
LinearWarmupLearningRate
PieceWarmupLearningRate
PolyLearningRate
SlopeLearningRate
StepLearningRate
invoke
