hello! 

I am writing a rust crate called caffe2op-rnn. 

It defines a mathematical operator used in DSP
and machine learning computations.

I would like you to help me write a rust crate
description for it.

Please write the description in the followin format:

<short description tag used in the crate header>
<double newline>
<longer, in depth description and mathematical analysis>
<END>

Below are listed some symbols, defined
or accessed from within this crate.

it is not guaranteed these tokens originate in
the crate, but many of them do. 

please be careful not to mention those that
seem only loosely related by name.

It is better to mention fewer tokens, as long
as they are the ones you identify as most
likely to reside in this crate.

If there are any mathematical ideas identified
by these tokens, please describe them
alongside the relevant mathematical equations. 

Last thing: please don't mention the word "token".

thanks!

please format your response for the Markdown .md file format.

here are the tokens:

Prefix
RecurrentNetworkBlobFetcher
RecurrentNetworkBlobFetcherOp
ScratchWorkspaceBlob
ScratchWorkspaces
currentBlob
currentStepWorkspace
currentTensor
extracted
newBlobName
newTensor
recurrent
stepWorkspaces
timestep

Analyzed
CUDARecurrentNetworkExecutor
ExecRange
RecurrentNetworkExecutorBase
Timestep
dep
depends
deps
direction
management
opportunities
recurrent
rnnexecutor
setMaxStreams
timestep
timesteps
tries

ALGO
BIDIRECTIONAL
CNTK
Cell
DROPOUT
Forget
Fully
GRU
GetRecurrentGradient
Hidden
InputData
LINEAR
NxD
OutputData
Recurrent
RecurrentGradient
RecurrentParamGet
RecurrentParamSet
SCRATCH
SKIP
STANDARD
TxNxD
UNIDIRECTIONAL
Validation
appropriate
batchSize
biasDesc
biasDims
correctness
cudnnCreateDropoutDescriptor
cudnnCreateRNNDescriptor
cudnnDestroyDropoutDescriptor
cudnnDestroyRNNDescriptor
cudnnDropoutGetStatesSize
cudnnFilterDescriptor
cudnnGetFilterNdDescriptor
cudnnGetRNNLinLayerBiasParams
cudnnGetRNNLinLayerMatrixParams
cudnnGetRNNParamsSize
cudnnGetRNNTrainingReserveSize
cudnnGetRNNWorkspaceSize
cudnnRNNBackwardData
cudnnRNNBackwardWeights
cudnnRNNForwardInference
cudnnRNNForwardTraining
cudnnSetDropoutDescriptor
cudnnSetFilterNdDescriptor
cudnnSetRNNDescriptor
cudnnSetTensorNdDescriptor
cudnnTensorFormat
cudnnWsNbytes
cy
descs
dictated
dropout
dropoutDesc
dropoutStates
efficiency
gru
hiddenSize
hy
inputDim
investigate
matDims
matrixParamDesc
minibatches
multiplying
numBiasDims
numDirections
numLayers
outputDim
paramsSize
pmatrix
reconsider
recurrent
reshapes
rnnDirection
rnnInput
rnnInputStr
rnnMode
rnnModeStr
seqLength
stateSize
tf
weightsSize

Bookkeeping
Dependencies
OpTask
Position
RNNApplyLinkOp
RNNNetOperator
ThreadedRecurrentNetworkExecutor
direction
recurrent
timestep
timesteps

AccumulateInputGradientOp
Accumulating
Accumulation
AddApplyLinkOps
AddGradientInputAccumulationOps
AddParamGradientAccumulationOps
Aliasing
CreateSharedBlobs
EnsureTimestepInitialized
GetRecurrentMapping
GetRecurrentNetworkGradient
HasInput
HasOutput
InitializeExecutor
Link
NumObserversStepNet
Offset
OffsetAlias
Offseting
PrependOps
RNNApplyLinkOp
RNNExecutor
RecurrentGradient
RecurrentInput
RecurrentNetworkExecutor
RecurrentNetworkExecutorBase
RecurrentNetworkGradient
RecurrentNetworkGradientOp
Renaming
Resetting
RunBackwards
ScratchWorkspaces
SetMaxParallelTimesteps
Sometimes
States
TEXT
Theano
UpdateTimestepBlob
Ws
accumulateFinalInputGradients
aliases
alternating
antyhing
ao
applyOffsetAlias
argsHelper
batchSize
bunch
cellGradient
constructAliases
constructLinks
constructParams
constructRecurrentGradients
constructRecurrentInputs
conveniently
createRNNExecutor
currentStepWorkspace
dep
dirrectly
examples
externalArg
externalData
externalGrad
externalTimestepSize
extractLinks
extractNetDef
fairly
flavor
frankly
fwd
gBlob
generality
gradInputs
gradientInputIndex
gradientInputs
gradientName
gradientOutputs
handy
initialStateLength
initializeBlobsToRecomputeOnBackward
initializeRecurrentInput
inputBlob
inputId
internalArg
internalDims
lastExternalGrad
lets
links
memonger
netString
numDstTimesteps
numSequences
oc
offsetArg
offseting
og
oglast
oglastBlob
pBlob
pGradientBlob
probaby
proceeds
races
recompute
recomputed
recurrent
recurrentGradients
recurrentInputIds
recurrentInputs
recurrentStateSize
remapped
remappedLink
remappedName
renameOpInputOutput
repeatCopy
rg
rgs
ris
rnnExecutor
seqLen
sequences
sharedBlobsWs
sharedWs
srcBlob
startDstTimestep
stateBlob
stateSize
stepNet
stepNetDef
stepWorkspaces
sums
timestep
timestepBlob
timesteps
tmpstep
trades
usability
window
windowArg
worry

AnalyzeOps
CUDARecurrentNetworkExecutor
CalculateInternalDependencies
Crash
EnsureTimestepInitialized
Exec
Firsrt
Frontier
HasOutput
Joining
Knock
LSTMs
Launch
OpTask
PrintInfo
RNNNetOperator
Race
RecurrentNetworkExecutor
RecurrentNetworkExecutorBase
RecurrentNetworkExecutorBaseTrait
RecurrentNetworkGradientOp
RunBackwards
RunOp
ThreadedRecurrentNetworkExecutor
Timestep
WorkerFunction
accounted
analyzed
arise
benefit
brand
comparisons
conflict
conflicting
countdown
counts
dep
depidx
deps
direction
forwardpass
fulfilled
ignoreLinkDependencies
incurs
links
multithreaded
odep
oit
opidx
outbound
outs
paralle
preceding
question
rec
recurent
recurrent
req
reusing
rit
rnnCopy
rnnexec
rnnexecutor
rotate
setNumThreads
timestep
timesteps
